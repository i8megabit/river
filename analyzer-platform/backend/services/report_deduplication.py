#!/usr/bin/env python3
"""
–°–µ—Ä–≤–∏—Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–æ–≤
–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à-id
"""

import hashlib
import os
from typing import Optional, Dict, Any, Tuple
from pathlib import Path
import logging

from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)


class ReportDeduplicator:
    """–ö–ª–∞—Å—Å –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à-id"""
    
    def __init__(self):
        pass
    
    def generate_report_hash(self, file_path: str, metadata: Optional[Dict[str, Any]] = None) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ö–µ—à –¥–ª—è –æ—Ç—á–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ:
        1. Hostname —Å–∏—Å—Ç–µ–º—ã
        2. –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–∏—Å—Ç–µ–º–µ (–û–°)
        3. –ö–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ–π —Å—É–º–º—ã –∫–ª—é—á–µ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –æ—Ç—á–µ—Ç–∞
        
        Args:
            file_path: –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É –æ—Ç—á–µ—Ç–∞
            metadata: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –°—Ç—Ä–æ–∫–∞ —Å —Ö–µ—à–µ–º –æ—Ç—á–µ—Ç–∞
        """
        try:
            if metadata is None:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
                metadata = self._extract_key_metadata(file_path)
            
            # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è —Ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ –∫–ª—é—á–µ–≤—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
            hash_components = [
                metadata.get('hostname', 'unknown'),
                metadata.get('os_name', ''),
                metadata.get('os_version', ''),
                # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ —Ö–µ—à–∞
                str(metadata.get('total_connections', 0)),
                str(metadata.get('tcp_ports_count', 0)),
                str(metadata.get('udp_ports_count', 0)),
            ]
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
            hash_string = '|'.join(str(component).strip() for component in hash_components)
            
            # –°–æ–∑–¥–∞–µ–º SHA-256 —Ö–µ—à
            hash_object = hashlib.sha256(hash_string.encode('utf-8'))
            content_hash = hash_object.hexdigest()
            
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ 16 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –∫—Ä–∞—Ç–∫–æ—Å—Ç–∏
            report_hash = content_hash[:16]
            
            logger.debug(f"üîó –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Ö–µ—à –æ—Ç—á–µ—Ç–∞: {report_hash} –¥–ª—è {metadata.get('hostname', 'unknown')}")
            logger.debug(f"üîó –•–µ—à –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã: {hash_string}")
            
            return report_hash
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ö–µ—à–∞ –æ—Ç—á–µ—Ç–∞: {e}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ö–µ—à –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            return hashlib.md5(os.path.basename(file_path).encode()).hexdigest()[:16]
    
    def generate_content_hash(self, file_path: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
        
        Args:
            file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É
            
        Returns:
            SHA-256 —Ö–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
        """
        try:
            with open(file_path, 'rb') as f:
                content = f.read()
                return hashlib.sha256(content).hexdigest()
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ö–µ—à–∞ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: {e}")
            return ""
    
    def _extract_key_metadata(self, file_path: str) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ HTML —Ñ–∞–π–ª–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ö–µ—à–∞
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –±—ã—Å—Ç—Ä—ã–π –º–µ—Ç–æ–¥ –±–µ–∑ –ø–æ–ª–Ω–æ–≥–æ –ø–∞—Ä—Å–∏–Ω–≥–∞
        
        Args:
            file_path: –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–µ–≤—ã–º–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        metadata = {
            'hostname': 'unknown',
            'os_name': '',
            'os_version': '',
            'total_connections': 0,
            'tcp_ports_count': 0,
            'udp_ports_count': 0
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            soup = BeautifulSoup(content, 'html.parser')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º hostname –∏–∑ title
            title = soup.find('title')
            if title:
                title_text = title.text
                if '–æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ -' in title_text.lower():
                    hostname_part = title_text.split('-')[-1].strip()
                    if hostname_part:
                        metadata['hostname'] = hostname_part
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ header-info —Å–µ–∫—Ü–∏–∏
            header_info_items = soup.find_all(class_='header-info-item')
            for item in header_info_items:
                text = item.text.strip()
                if 'üíª –û–°:' in text:
                    os_info = text.replace('üíª –û–°:', '').strip()
                    parts = os_info.split(' ', 1)
                    metadata['os_name'] = parts[0]
                    if len(parts) > 1:
                        metadata['os_version'] = parts[1]
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ stat-number —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            stat_cards = soup.find_all(class_='stat-card')
            for card in stat_cards:
                stat_number = card.find(class_='stat-number')
                stat_label = card.find(class_='stat-label')
                
                if stat_number and stat_label:
                    number = self._extract_number(stat_number.text)
                    label = stat_label.text.strip().lower()
                    
                    if '—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π' in label and '–≤—Å–µ–≥–æ' in label:
                        metadata['total_connections'] = number
                    elif 'tcp –ø–æ—Ä—Ç–æ–≤' in label:
                        metadata['tcp_ports_count'] = number
                    elif 'udp –ø–æ—Ä—Ç–æ–≤' in label:
                        metadata['udp_ports_count'] = number
            
            logger.debug(f"üîç –ò–∑–≤–ª–µ—á–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
        
        return metadata
    
    def _extract_number(self, text: str) -> int:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            import re
            clean_text = re.sub(r'[^\d]', '', text)
            return int(clean_text) if clean_text else 0
        except (ValueError, TypeError):
            return 0
    
    def find_duplicate_reports_by_hash(self, target_hash: str, uploads_dir: str) -> list:
        """
        –ù–∞—Ö–æ–¥–∏—Ç –æ—Ç—á–µ—Ç—ã —Å —Ç–∞–∫–∏–º –∂–µ —Ö–µ—à–µ–º –≤ –ø–∞–ø–∫–µ uploads
        
        Args:
            target_hash: –ò—Å–∫–æ–º—ã–π —Ö–µ—à
            uploads_dir: –ü–∞–ø–∫–∞ —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –æ—Ç—á–µ—Ç–∞–º–∏
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º —Å —Ç–∞–∫–∏–º –∂–µ —Ö–µ—à–µ–º
        """
        duplicates = []
        
        try:
            if not os.path.exists(uploads_dir):
                return duplicates
            
            for filename in os.listdir(uploads_dir):
                if filename.endswith('.html'):
                    file_path = os.path.join(uploads_dir, filename)
                    
                    try:
                        file_hash = self.generate_report_hash(file_path)
                        if file_hash == target_hash:
                            duplicates.append(file_path)
                            logger.debug(f"üîç –ù–∞–π–¥–µ–Ω –¥—É–±–ª–∏–∫–∞—Ç: {filename} (—Ö–µ—à: {file_hash})")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ñ–∞–π–ª–∞ {filename}: {e}")
                        continue
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤: {e}")
        
        return duplicates
    
    def create_filename_from_hash(self, report_hash: str, original_filename: str) -> str:
        """
        –°–æ–∑–¥–∞–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à–∞ –æ—Ç—á–µ—Ç–∞
        
        Args:
            report_hash: –•–µ—à –æ—Ç—á–µ—Ç–∞
            original_filename: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            
        Returns:
            –ù–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        """
        try:
            file_extension = os.path.splitext(original_filename)[1]
            return f"report_{report_hash}{file_extension}"
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: {e}")
            return original_filename


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–µ–¥—É–ø–ª–∏–∫–∞—Ç–æ—Ä–∞
report_deduplicator = ReportDeduplicator()


def generate_report_hash(file_path: str, metadata: Optional[Dict[str, Any]] = None) -> str:
    """
    –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ö–µ—à–∞ –æ—Ç—á–µ—Ç–∞
    
    Args:
        file_path: –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É –æ—Ç—á–µ—Ç–∞
        metadata: –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        
    Returns:
        –°—Ç—Ä–æ–∫–∞ —Å —Ö–µ—à–µ–º –æ—Ç—á–µ—Ç–∞
    """
    return report_deduplicator.generate_report_hash(file_path, metadata)


def find_duplicate_reports(target_hash: str, uploads_dir: str) -> list:
    """
    –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –æ—Ç—á–µ—Ç–æ–≤
    
    Args:
        target_hash: –ò—Å–∫–æ–º—ã–π —Ö–µ—à
        uploads_dir: –ü–∞–ø–∫–∞ —Å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º–∏ –æ—Ç—á–µ—Ç–∞–º–∏
        
    Returns:
        –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º —Å —Ç–∞–∫–∏–º –∂–µ —Ö–µ—à–µ–º
    """
    return report_deduplicator.find_duplicate_reports_by_hash(target_hash, uploads_dir)


def create_hash_based_filename(report_hash: str, original_filename: str) -> str:
    """
    –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à–∞
    
    Args:
        report_hash: –•–µ—à –æ—Ç—á–µ—Ç–∞
        original_filename: –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
        
    Returns:
        –ù–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
    """
    return report_deduplicator.create_filename_from_hash(report_hash, original_filename)


if __name__ == "__main__":
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ç–æ—Ä–∞ –æ—Ç—á–µ—Ç–æ–≤
    """
    
    def test_deduplicator():
        print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–µ–¥—É–ø–ª–∏–∫–∞—Ç–æ—Ä–∞ –æ—Ç—á–µ—Ç–æ–≤...")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π HTML –∫–æ–Ω—Ç–µ–Ω—Ç
        test_html = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>–ö—É–º—É–ª—è—Ç–∏–≤–Ω—ã–π –æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ - test-host</title>
        </head>
        <body>
            <div class="header-info">
                <div class="header-info-item">üíª –û–°: macOS 14.5.0</div>
            </div>
            <div class="stats">
                <div class="stat-card">
                    <div class="stat-number">15</div>
                    <div class="stat-label">–í—Å–µ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">8</div>
                    <div class="stat-label">TCP –ø–æ—Ä—Ç–æ–≤</div>
                </div>
                <div class="stat-card">
                    <div class="stat-number">3</div>
                    <div class="stat-label">UDP –ø–æ—Ä—Ç–æ–≤</div>
                </div>
            </div>
        </body>
        </html>
        """
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
        test_file = "test_report.html"
        with open(test_file, 'w', encoding='utf-8') as f:
            f.write(test_html)
        
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ö–µ—à
            report_hash = generate_report_hash(test_file)
            print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω —Ö–µ—à: {report_hash}")
            
            # –°–æ–∑–¥–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–µ—à–∞
            new_filename = create_hash_based_filename(report_hash, test_file)
            print(f"‚úÖ –ù–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞: {new_filename}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ö–µ—à–∞
            report_hash2 = generate_report_hash(test_file)
            print(f"‚úÖ –ü–æ–≤—Ç–æ—Ä–Ω—ã–π —Ö–µ—à: {report_hash2}")
            print(f"‚úÖ –•–µ—à–∏ —Å–æ–≤–ø–∞–¥–∞—é—Ç: {report_hash == report_hash2}")
            
        finally:
            # –£–¥–∞–ª—è–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª
            if os.path.exists(test_file):
                os.remove(test_file)
    
    test_deduplicator() 