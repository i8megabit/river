#!/usr/bin/env python3
"""
–°–µ—Ä–≤–∏—Å –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML –æ—Ç—á–µ—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
–¢–æ—á–Ω–æ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É HTML –æ—Ç—á–µ—Ç–æ–≤, —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–æ–º
"""

import os
import re
import json
import hashlib
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import logging
from bs4 import BeautifulSoup, Tag

from core.config import get_settings

logger = logging.getLogger(__name__)
settings = get_settings()


class AnalyzerHTMLParser:
    """
    –ü–∞—Ä—Å–µ—Ä HTML –æ—Ç—á–µ—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ HTML —Ñ–∞–π–ª–æ–≤, —Ç–æ—á–Ω–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ
    –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä—É –æ—Ç—á–µ—Ç–æ–≤ –≤ analyzer_utils.py::generate_simple_html_report
    """
    
    def __init__(self):
        self.supported_sections = [
            'overview',
            'connections', 
            'ports',
            'network',
            'changes',
            'details'
        ]
    
    async def parse_html_report(self, file_path: str) -> Dict[str, Any]:
        """
        –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML –æ—Ç—á–µ—Ç–∞
        
        Args:
            file_path: –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É
            
        Returns:
            –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç–∞
        """
        try:
            # –ß–∏—Ç–∞–µ–º HTML —Ñ–∞–π–ª
            with open(file_path, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # –ü–∞—Ä—Å–∏–º HTML
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            metadata = self._extract_metadata(soup, file_path)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ header
            header_info = self._extract_header_info(soup)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ overview —Å–µ–∫—Ü–∏–∏
            overview_stats = self._extract_overview_stats(soup)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
            connections = self._extract_connections(soup)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–æ—Ä—Ç—ã
            ports = self._extract_ports(soup)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–µ—Ç–µ–≤—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ macOS)
            network_interfaces = []
            if header_info.get('os_name', '').lower() not in ['darwin', 'macos']:
                network_interfaces = self._extract_network_interfaces(soup)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –∏–∑–º–µ–Ω–µ–Ω–∏–π
            change_history = self._extract_change_history(soup)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ä—Ç–æ–≤
            tcp_ports_count = len(ports.get('tcp', []))
            udp_ports_count = len(ports.get('udp', []))
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
            parsed_data = {
                **metadata,
                **header_info,
                **overview_stats,
                'connections': connections,
                'ports': ports,
                'tcp_ports_count': tcp_ports_count,
                'udp_ports_count': udp_ports_count,
                'network_interfaces': network_interfaces,
                'change_history': change_history,
                'raw_html': html_content[:1000],  # –ü–µ—Ä–≤—ã–µ 1000 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
                'parsing_timestamp': datetime.utcnow().isoformat()
            }
            
            logger.info(f"‚úÖ HTML –æ—Ç—á–µ—Ç —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω: {os.path.basename(file_path)}")
            return parsed_data
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML –æ—Ç—á–µ—Ç–∞ {file_path}: {e}")
            raise
    
    def _extract_metadata(self, soup: BeautifulSoup, file_path: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ HTML –≤–∫–ª—é—á–∞—è —Ö–µ—à –∏ ID –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        try:
            # –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            title_tag = soup.find('title')
            report_title = title_tag.text if title_tag else "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –æ—Ç—á–µ—Ç"
            
            # –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = os.path.getsize(file_path)
            
            # –•–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞
            with open(file_path, 'rb') as f:
                content_hash = hashlib.sha256(f.read()).hexdigest()
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º analyzer –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            analyzer_metadata = {}
            meta_tags = soup.find_all('meta')
            
            for meta in meta_tags:
                name = meta.get('name', '')
                content = meta.get('content', '')
                
                if name == 'analyzer-report-hash':
                    analyzer_metadata['report_hash'] = content
                elif name == 'analyzer-report-id':
                    analyzer_metadata['report_id'] = content
                elif name == 'analyzer-hostname':
                    analyzer_metadata['hostname'] = content
                elif name == 'analyzer-generated-at':
                    analyzer_metadata['generated_at'] = content
                elif name == 'analyzer-version':
                    analyzer_metadata['analyzer_version'] = content
                elif name == 'analyzer-hash-components':
                    analyzer_metadata['hash_components'] = content
            
            # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            if analyzer_metadata:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞:")
                if 'report_hash' in analyzer_metadata:
                    logger.info(f"   üîê –•–µ—à –æ—Ç—á–µ—Ç–∞: {analyzer_metadata['report_hash']}")
                if 'report_id' in analyzer_metadata:
                    logger.info(f"   üîë ID –æ—Ç—á–µ—Ç–∞: {analyzer_metadata['report_id']}")
                if 'hash_components' in analyzer_metadata:
                    logger.info(f"   üìä –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Ö–µ—à–∞: {analyzer_metadata['hash_components']}")
            else:
                logger.warning("‚ö†Ô∏è –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã - –≤–æ–∑–º–æ–∂–Ω–æ —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç –æ—Ç—á–µ—Ç–∞")
            
            metadata = {
                'report_title': report_title,
                'file_size': file_size,
                'content_hash': content_hash,
                'file_path': file_path,
                'filename': os.path.basename(file_path)
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–∞–π–¥–µ–Ω—ã
            metadata.update(analyzer_metadata)
            
            return metadata
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
            return {}
    
    def _extract_header_info(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ header —Å–µ–∫—Ü–∏–∏ HTML
        –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç header-info-item —ç–ª–µ–º–µ–Ω—Ç–∞–º
        """
        try:
            header_info = {}
            
            # –ò—â–µ–º header-info-item —ç–ª–µ–º–µ–Ω—Ç—ã
            header_items = soup.find_all(class_='header-info-item')
            
            for item in header_items:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–ª—é—á –∏–∑ strong —Ç–µ–≥–∞
                strong_tag = item.find('strong')
                if strong_tag:
                    key = strong_tag.text.strip('üñ•Ô∏èüíªüöÄüîÑüìä:').strip()
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ
                    value_div = item.find(class_='header-info-value')
                    if value_div:
                        value = value_div.text.strip()
                    else:
                        # –ï—Å–ª–∏ –Ω–µ—Ç header-info-value, –±–µ—Ä–µ–º –≤–µ—Å—å —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ strong
                        value = item.text.replace(strong_tag.text, '').strip()
                    
                    # –ú–∞–ø–∏–º –∫–ª—é—á–∏ –Ω–∞ –Ω–∞—à–∏ –ø–æ–ª—è
                    if '–•–æ—Å—Ç' in key:
                        header_info['hostname'] = value
                    elif '–û–°' in key or '–û–ø–µ—Ä–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞' in key:
                        # –†–∞–∑–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫—É –û–° –Ω–∞ name –∏ version
                        if value and value != 'unknown':
                            parts = value.split(' ', 1)
                            header_info['os_name'] = parts[0]
                            if len(parts) > 1:
                                header_info['os_version'] = parts[1]
                            else:
                                header_info['os_version'] = ''
                        else:
                            header_info['os_name'] = value or 'Unknown'
                            header_info['os_version'] = ''
                    elif '–ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫' in key:
                        header_info['first_run'] = self._parse_datetime(value)
                    elif '–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ' in key:
                        header_info['last_update'] = self._parse_datetime(value)
                    elif '–∏–∑–º–µ—Ä–µ–Ω–∏–π' in key or '–ò–∑–º–µ—Ä–µ–Ω–∏–π' in key:
                        header_info['total_measurements'] = self._extract_number(value)
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –û–° –≤ header-info, –∏—â–µ–º –≤ –º–µ—Ç–∞—Ç–µ–≥–∞—Ö
            if 'os_name' not in header_info or not header_info['os_name']:
                meta_tags = soup.find_all('meta')
                for meta in meta_tags:
                    name = meta.get('name', '')
                    content = meta.get('content', '')
                    
                    if name == 'analyzer-os-name':
                        header_info['os_name'] = content
                    elif name == 'analyzer-os-version':
                        header_info['os_version'] = content
                    elif name == 'analyzer-os-full':
                        # –ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –û–° –≤ –æ–¥–Ω–æ–º –ø–æ–ª–µ
                        if content:
                            parts = content.split(' ', 1)
                            header_info['os_name'] = parts[0]
                            if len(parts) > 1:
                                header_info['os_version'] = parts[1]
                            else:
                                header_info['os_version'] = ''
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ hostname –≤ header-info, –∏—â–µ–º –≤ –∑–∞–≥–æ–ª–æ–≤–∫–µ –∏–ª–∏ title
            if 'hostname' not in header_info:
                # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º title
                title_tag = soup.find('title')
                if title_tag and '–æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ -' in title_tag.text.lower():
                    hostname = title_tag.text.split('-')[-1].strip()
                    header_info['hostname'] = hostname
                else:
                    # –ü–æ—Ç–æ–º h1
                    h1_tag = soup.find('h1')
                    if h1_tag:
                        # –ï—Å–ª–∏ —ç—Ç–æ "Analyzer", –∏—â–µ–º hostname –≤ –¥—Ä—É–≥–æ–º –º–µ—Å—Ç–µ
                        if h1_tag.text.strip() == 'Analyzer':
                            # –ò—â–µ–º –≤ title
                            if title_tag:
                                title_text = title_tag.text
                                if ' - ' in title_text:
                                    hostname = title_text.split(' - ')[-1].strip()
                                    header_info['hostname'] = hostname
                        elif '–æ—Ç—á–µ—Ç –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ -' in h1_tag.text.lower():
                            hostname = h1_tag.text.split('-')[-1].strip()
                            header_info['hostname'] = hostname
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à–ª–∏
            if 'os_name' not in header_info or not header_info['os_name'] or header_info['os_name'] == 'unknown':
                header_info['os_name'] = 'Unknown'
            
            if 'os_version' not in header_info:
                header_info['os_version'] = ''
            
            logger.debug(f"üìä –ò–∑–≤–ª–µ—á–µ–Ω–∞ header info: hostname={header_info.get('hostname')}, os={header_info.get('os_name')} {header_info.get('os_version')}")
            
            return header_info
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è header info: {e}")
            return {}
    
    def _extract_overview_stats(self, soup: BeautifulSoup) -> Dict[str, Any]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ overview —Å–µ–∫—Ü–∏–∏
        –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç stat-card —ç–ª–µ–º–µ–Ω—Ç–∞–º
        """
        try:
            stats = {}
            
            # –ò—â–µ–º stat-card —ç–ª–µ–º–µ–Ω—Ç—ã
            stat_cards = soup.find_all(class_='stat-card')
            
            for card in stat_cards:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                number_div = card.find(class_='stat-number')
                label_div = card.find(class_='stat-label')
                
                if number_div and label_div:
                    number = self._extract_number(number_div.text)
                    label = label_div.text.strip().lower()
                    
                    # –ú–∞–ø–∏–º –ª–µ–π–±–ª—ã –Ω–∞ –Ω–∞—à–∏ –ø–æ–ª—è (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º —Ä—É—Å—Å–∫–∏–π –∏ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π)
                    if '–≤—Å–µ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π' in label or 'total connections' in label:
                        stats['total_connections'] = number
                    elif '–≤—Ö–æ–¥—è—â–∏—Ö' in label or 'incoming' in label:
                        stats['incoming_connections'] = number
                    elif '–∏—Å—Ö–æ–¥—è—â–∏—Ö' in label or 'outgoing' in label:
                        stats['outgoing_connections'] = number
                    elif '–ø—Ä–æ—Ü–µ—Å—Å–æ–≤' in label or 'processes' in label:
                        stats['unique_processes'] = number
                    elif '—É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Ö–æ—Å—Ç–æ–≤' in label or 'remote hosts' in label:
                        stats['unique_hosts'] = number
                    # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –ø–æ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞–º
                    elif 'tcp —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π' in label or 'tcp connections' in label:
                        stats['tcp_connections'] = number
                    elif 'udp —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π' in label or 'udp connections' in label:
                        stats['udp_connections'] = number
                    elif 'icmp —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π' in label or 'icmp connections' in label:
                        stats['icmp_connections'] = number
                    elif 'tcp –ø–æ—Ä—Ç–æ–≤' in label or 'tcp ports' in label:
                        stats['tcp_ports_count'] = number
                    elif 'udp –ø–æ—Ä—Ç–æ–≤' in label or 'udp ports' in label:
                        stats['udp_ports_count'] = number
                    elif '—Å–æ–±—ã—Ç–∏–π –∏–∑–º–µ–Ω–µ–Ω–∏–π' in label or 'change events' in label or '–∏–∑–º–µ–Ω–µ–Ω–∏–π' in label:
                        stats['change_events_count'] = number
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –æ—Å–Ω–æ–≤–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≤ stat-card, –ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã
            if not stats.get('total_connections'):
                # –ò—â–µ–º –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö —Å–µ–∫—Ü–∏–π
                sections = soup.find_all('h3')
                for section in sections:
                    section_text = section.text
                    if '–∞–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è' in section_text.lower():
                        # –ò—â–µ–º —á–∏—Å–ª–æ –≤ —Å–∫–æ–±–∫–∞—Ö —Ç–∏–ø–∞ "–ê–∫—Ç–∏–≤–Ω—ã–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (57)"
                        import re
                        match = re.search(r'\((\d+)\)', section_text)
                        if match:
                            stats['total_connections'] = int(match.group(1))
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ progress-bars –µ—Å–ª–∏ –µ—Å—Ç—å
            progress_bars = soup.find_all(class_='progress-item')
            for bar in progress_bars:
                label_div = bar.find(class_='progress-label')
                value_div = bar.find(class_='progress-value')
                
                if label_div and value_div:
                    label = label_div.text.strip().lower()
                    value = self._extract_number(value_div.text)
                    
                    if label == 'tcp':
                        stats['tcp_connections'] = value
                    elif label == 'udp':
                        stats['udp_connections'] = value
                    elif label == 'icmp':
                        stats['icmp_connections'] = value
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏
            if not stats.get('total_connections'):
                tcp = stats.get('tcp_connections', 0)
                udp = stats.get('udp_connections', 0)
                icmp = stats.get('icmp_connections', 0)
                if tcp or udp or icmp:
                    stats['total_connections'] = tcp + udp + icmp
            
            # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            logger.info(f"üìä –ò–∑–≤–ª–µ—á–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ overview:")
            logger.info(f"   üîó –í—Å–µ–≥–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {stats.get('total_connections', 0)}")
            logger.info(f"   üì° TCP —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {stats.get('tcp_connections', 0)}")
            logger.info(f"   üì° UDP —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {stats.get('udp_connections', 0)}")
            logger.info(f"   üì° ICMP —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {stats.get('icmp_connections', 0)}")
            logger.info(f"   üì• –í—Ö–æ–¥—è—â–∏—Ö: {stats.get('incoming_connections', 0)}")
            logger.info(f"   üì§ –ò—Å—Ö–æ–¥—è—â–∏—Ö: {stats.get('outgoing_connections', 0)}")
            logger.info(f"   üö™ TCP –ø–æ—Ä—Ç–æ–≤: {stats.get('tcp_ports_count', 0)}")
            logger.info(f"   üö™ UDP –ø–æ—Ä—Ç–æ–≤: {stats.get('udp_ports_count', 0)}")
            
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ overview: {e}")
            return {}
    
    def _extract_connections(self, soup: BeautifulSoup) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∏–∑ connections-table
        """
        try:
            connections = []
            
            # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π
            connections_table = soup.find(class_='connections-table')
            if not connections_table:
                return connections
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
            rows = connections_table.find('tbody').find_all('tr') if connections_table.find('tbody') else []
            
            for row in rows:
                cells = row.find_all('td')
                if len(cells) >= 6:  # –ú–∏–Ω–∏–º—É–º 6 –∫–æ–ª–æ–Ω–æ–∫
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å —É—á–µ—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã HTML
                    direction_text = self._clean_text(cells[0].text)
                    local_address = self._clean_text(cells[1].text)
                    remote_address = self._clean_text(cells[2].text)
                    process_name = self._clean_text(cells[3].text)
                    
                    # –ü—Ä–æ—Ç–æ–∫–æ–ª –º–æ–∂–µ—Ç –±—ã—Ç—å –≤ span —Å –∫–ª–∞—Å—Å–æ–º
                    protocol_cell = cells[4]
                    protocol_span = protocol_cell.find('span')
                    if protocol_span:
                        protocol = protocol_span.text.strip()
                        # –£–±–∏—Ä–∞–µ–º CSS –∫–ª–∞—Å—Å—ã –∏–∑ –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
                        if protocol_span.get('class'):
                            for cls in protocol_span.get('class'):
                                if cls.startswith('protocol-'):
                                    protocol = cls.replace('protocol-', '').upper()
                                    break
                    else:
                        protocol = self._clean_text(protocol_cell.text)
                    
                    last_seen = self._clean_text(cells[5].text)
                    
                    # –°—á–µ—Ç—á–∏–∫ –ø–∞–∫–µ—Ç–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å 7-—è –∫–æ–ª–æ–Ω–∫–∞)
                    packet_count = 1
                    if len(cells) >= 7:
                        count_text = self._clean_text(cells[6].text)
                        packet_count = self._extract_number(count_text)
                    
                    connection = {
                        'direction': direction_text,
                        'local_address': local_address,
                        'remote_address': remote_address,
                        'process_name': process_name,
                        'protocol': protocol,
                        'last_seen': last_seen,
                        'packet_count': packet_count
                    }
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                    if 'üì•' in direction_text or '–≤—Ö–æ–¥—è—â–µ–µ' in direction_text.lower():
                        connection['connection_type'] = 'incoming'
                    elif 'üì§' in direction_text or '–∏—Å—Ö–æ–¥—è—â–µ–µ' in direction_text.lower():
                        connection['connection_type'] = 'outgoing'
                    else:
                        connection['connection_type'] = 'unknown'
                    
                    # –ü–∞—Ä—Å–∏–º –ª–æ–∫–∞–ª—å–Ω—ã–π –∏ —É–¥–∞–ª–µ–Ω–Ω—ã–π –∞–¥—Ä–µ—Å–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ—Ä—Ç–æ–≤
                    if ':' in local_address and local_address != '*:*':
                        try:
                            if local_address.startswith('*:'):
                                connection['local_port'] = local_address.split(':')[-1]
                            else:
                                addr_parts = local_address.rsplit(':', 1)
                                connection['local_ip'] = addr_parts[0]
                                connection['local_port'] = addr_parts[1]
                        except (IndexError, ValueError):
                            pass
                    
                    if ':' in remote_address and remote_address != '*:*':
                        try:
                            if remote_address.startswith('*:'):
                                connection['remote_port'] = remote_address.split(':')[-1]
                            else:
                                addr_parts = remote_address.rsplit(':', 1)
                                connection['remote_ip'] = addr_parts[0]
                                connection['remote_port'] = addr_parts[1]
                        except (IndexError, ValueError):
                            pass
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
                    if remote_address == '*:*':
                        connection['state'] = 'listening'
                    else:
                        connection['state'] = 'established'
                    
                    connections.append(connection)
            
            logger.debug(f"üìä –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(connections)} —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π")
            return connections
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {e}")
            return []
    
    def _extract_ports(self, soup: BeautifulSoup) -> Dict[str, List[Dict[str, Any]]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ—Ä—Ç—ã –∏–∑ ports-grid —Å–µ–∫—Ü–∏–π
        """
        try:
            ports = {'tcp': [], 'udp': []}
            
            # –ò—â–µ–º —Å–µ–∫—Ü–∏—é –ø–æ—Ä—Ç–æ–≤ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫—É
            ports_section = soup.find('div', id='ports')
            if not ports_section:
                logger.warning("üö™ –°–µ–∫—Ü–∏—è –ø–æ—Ä—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
                return self._extract_ports_from_stats(soup)
            
            # –ò—â–µ–º TCP –ø–æ—Ä—Ç—ã - –Ω–∞—Ö–æ–¥–∏–º h3 —Å —Ç–µ–∫—Å—Ç–æ–º "TCP –ø–æ—Ä—Ç—ã" –∏ –∑–∞—Ç–µ–º –±–ª–∏–∂–∞–π—à–∏–π ports-grid
            tcp_header = ports_section.find(['h3', 'h4'], string=lambda text: text and 'TCP –ø–æ—Ä—Ç—ã' in text)
            if tcp_header:
                tcp_grid = tcp_header.find_next_sibling('div', class_='ports-grid')
                if tcp_grid:
                    tcp_items = tcp_grid.find_all('div', class_='port-item')
                    logger.debug(f"üîç –ù–∞–π–¥–µ–Ω–æ TCP —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(tcp_items)}")
                    
                    for item in tcp_items:
                        port_number_div = item.find('div', class_='port-number')
                        port_desc_div = item.find('div', class_='port-desc')
                        
                        if port_number_div:
                            try:
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
                                port_text = port_number_div.get_text().strip()
                                logger.debug(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º TCP –ø–æ—Ä—Ç: '{port_text}'")
                                
                                # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "TCP " –µ—Å–ª–∏ –µ—Å—Ç—å
                                if port_text.startswith('TCP '):
                                    port_text = port_text[4:]
                                
                                port_number = int(port_text)
                                description = port_desc_div.get_text().strip() if port_desc_div else f"TCP –ø–æ—Ä—Ç {port_number}"
                                
                                ports['tcp'].append({
                                    'port_number': port_number,
                                    'protocol': 'tcp',
                                    'description': description,
                                    'status': 'listening'
                                })
                                logger.debug(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω TCP –ø–æ—Ä—Ç: {port_number}")
                            except (ValueError, AttributeError) as e:
                                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ TCP –ø–æ—Ä—Ç–∞ '{port_text}': {e}")
                                continue
            
            # –ò—â–µ–º UDP –ø–æ—Ä—Ç—ã –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ
            udp_header = ports_section.find(['h3', 'h4'], string=lambda text: text and 'UDP –ø–æ—Ä—Ç—ã' in text)
            if udp_header:
                udp_grid = udp_header.find_next_sibling('div', class_='ports-grid')
                if udp_grid:
                    udp_items = udp_grid.find_all('div', class_='port-item')
                    logger.debug(f"üîç –ù–∞–π–¥–µ–Ω–æ UDP —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {len(udp_items)}")
                    
                    for item in udp_items:
                        port_number_div = item.find('div', class_='port-number')
                        port_desc_div = item.find('div', class_='port-desc')
                        
                        if port_number_div:
                            try:
                                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å –ø—Ä–æ—Ç–æ–∫–æ–ª–∞
                                port_text = port_number_div.get_text().strip()
                                logger.debug(f"üîç –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º UDP –ø–æ—Ä—Ç: '{port_text}'")
                                
                                # –£–±–∏—Ä–∞–µ–º –ø—Ä–µ—Ñ–∏–∫—Å "UDP " –µ—Å–ª–∏ –µ—Å—Ç—å
                                if port_text.startswith('UDP '):
                                    port_text = port_text[4:]
                                
                                port_number = int(port_text)
                                description = port_desc_div.get_text().strip() if port_desc_div else f"UDP –ø–æ—Ä—Ç {port_number}"
                                
                                ports['udp'].append({
                                    'port_number': port_number,
                                    'protocol': 'udp',
                                    'description': description,
                                    'status': 'listening'
                                })
                                logger.debug(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω UDP –ø–æ—Ä—Ç: {port_number}")
                            except (ValueError, AttributeError) as e:
                                logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ UDP –ø–æ—Ä—Ç–∞ '{port_text}': {e}")
                                continue
            
            total_ports = len(ports['tcp']) + len(ports['udp'])
            logger.info(f"üö™ –ò–∑–≤–ª–µ—á–µ–Ω–æ {total_ports} –ø–æ—Ä—Ç–æ–≤ (TCP: {len(ports['tcp'])}, UDP: {len(ports['udp'])})")
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –ø–æ—Ä—Ç—ã –≤ —Å–µ–∫—Ü–∏–∏, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            if total_ports == 0:
                logger.warning("üö™ –ü–æ—Ä—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ —Å–µ–∫—Ü–∏–∏, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
                return self._extract_ports_from_stats(soup)
            
            return ports
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ—Ä—Ç–æ–≤: {e}")
            return {'tcp': [], 'udp': []}
    
    def _extract_ports_from_stats(self, soup: BeautifulSoup) -> Dict[str, List[Dict[str, Any]]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Ä—Ç–∞—Ö –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Å–µ–∫—Ü–∏–∏ –µ—Å–ª–∏ –æ—Å–Ω–æ–≤–Ω–∞—è —Å–µ–∫—Ü–∏—è –ø–æ—Ä—Ç–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞
        """
        try:
            ports = {'tcp': [], 'udp': []}
            
            # –ò—â–µ–º –≤ stat-card —ç–ª–µ–º–µ–Ω—Ç–∞—Ö (—Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
            stat_cards = soup.find_all('div', class_='stat-card')
            
            tcp_count = 0
            udp_count = 0
            
            for card in stat_cards:
                stat_number = card.find('div', class_='stat-number')
                stat_label = card.find('div', class_='stat-label')
                
                if stat_number and stat_label:
                    try:
                        value = int(stat_number.get_text().strip())
                        label = stat_label.get_text().strip().lower()
                    except ValueError:
                        continue
                    
                    # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–æ—Ä—Ç–æ–≤ –≤ –º–µ—Ç–∫–∞—Ö
                    if 'tcp' in label and '–ø–æ—Ä—Ç' in label and value > 0:
                        tcp_count = value
                    elif 'udp' in label and '–ø–æ—Ä—Ç' in label and value > 0:
                        udp_count = value
                    elif '–ø–æ—Ä—Ç' in label and value > 0:
                        # –ï—Å–ª–∏ –æ–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Ä—Ç–æ–≤, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º —á—Ç–æ –ø–æ–ª–æ–≤–∏–Ω–∞ TCP, –ø–æ–ª–æ–≤–∏–Ω–∞ UDP
                        tcp_count = value // 2
                        udp_count = value - tcp_count
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫–∏ –ø–æ—Ä—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            for i in range(min(tcp_count, 20)):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 20
                ports['tcp'].append({
                    'port_number': 80 + i,
                    'protocol': 'tcp',
                    'description': f"TCP –ø–æ—Ä—Ç {80 + i} (–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)",
                    'status': 'listening'
                })
            
            for i in range(min(udp_count, 20)):
                ports['udp'].append({
                    'port_number': 53 + i,
                    'protocol': 'udp',  
                    'description': f"UDP –ø–æ—Ä—Ç {53 + i} (–∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)",
                    'status': 'listening'
                })
            
            total_ports = len(ports['tcp']) + len(ports['udp'])
            if total_ports > 0:
                logger.info(f"üö™ –°–æ–∑–¥–∞–Ω–æ {total_ports} –∑–∞–≥–ª—É—à–µ–∫ –ø–æ—Ä—Ç–æ–≤ –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ (TCP: {len(ports['tcp'])}, UDP: {len(ports['udp'])})")
            
            return ports
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–æ—Ä—Ç–æ–≤ –∏–∑ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏: {e}")
            return {'tcp': [], 'udp': []}
    
    def _extract_network_interfaces(self, soup: BeautifulSoup) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å–µ—Ç–µ–≤—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã –∏–∑ network-stats-grid
        """
        try:
            interfaces = []
            
            # –ò—â–µ–º interface-card —ç–ª–µ–º–µ–Ω—Ç—ã
            interface_cards = soup.find_all(class_='interface-card')
            
            for card in interface_cards:
                interface_name_div = card.find(class_='interface-name')
                if not interface_name_div:
                    continue
                
                interface_data = {
                    'interface_name': interface_name_div.text.strip(),
                    'packets_in': 0,
                    'packets_out': 0,
                    'bytes_in': 0,
                    'bytes_out': 0
                }
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏–∑ interface-stat —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                stats = card.find_all(class_='interface-stat')
                for stat in stats:
                    value_div = stat.find(class_='interface-stat-value')
                    label_div = stat.find(class_='interface-stat-label')
                    
                    if value_div and label_div:
                        value = self._extract_number(value_div.text)
                        label = label_div.text.strip().lower()
                        
                        if '–ø–∞–∫–µ—Ç—ã –≤—Ö–æ–¥—è—â–∏–µ' in label:
                            interface_data['packets_in'] = value
                        elif '–ø–∞–∫–µ—Ç—ã –∏—Å—Ö–æ–¥—è—â–∏–µ' in label:
                            interface_data['packets_out'] = value
                        elif '–±–∞–π—Ç—ã –≤—Ö–æ–¥—è—â–∏–µ' in label:
                            interface_data['bytes_in'] = value
                        elif '–±–∞–π—Ç—ã –∏—Å—Ö–æ–¥—è—â–∏–µ' in label:
                            interface_data['bytes_out'] = value
                
                interfaces.append(interface_data)
            
            logger.debug(f"üì° –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(interfaces)} —Å–µ—Ç–µ–≤—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤")
            return interfaces
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å–µ—Ç–µ–≤—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤: {e}")
            return []
    
    def _extract_change_history(self, soup: BeautifulSoup) -> List[Dict[str, Any]]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –∏–∑–º–µ–Ω–µ–Ω–∏–π –∏–∑ changes-timeline
        """
        try:
            changes = []
            
            # –ò—â–µ–º change-item —ç–ª–µ–º–µ–Ω—Ç—ã
            change_items = soup.find_all(class_='change-item')
            
            for item in change_items:
                timestamp_div = item.find(class_='change-timestamp')
                details_div = item.find(class_='change-details')
                
                if timestamp_div:
                    timestamp_text = timestamp_div.text.strip()
                    
                    # –ü–∞—Ä—Å–∏–º —Å—Ç—Ä–æ–∫—É —Ç–∏–ø–∞ "üöÄ –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ #1 - 25.12.2024 10:30:45"
                    change_data = {
                        'change_timestamp': self._extract_datetime_from_change(timestamp_text),
                        'is_first_run': 'üöÄ' in timestamp_text or '–ø–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫' in timestamp_text.lower(),
                        'measurement_id': self._extract_measurement_id(timestamp_text),
                        'change_details': details_div.text.strip() if details_div else '',
                        'changed_categories': []
                    }
                    
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π –∏–∑ –¥–µ—Ç–∞–ª–µ–π
                    if details_div:
                        details_text = details_div.text.lower()
                        if 'connections' in details_text:
                            change_data['changed_categories'].append('connections')
                        if 'ports' in details_text:
                            change_data['changed_categories'].append('ports')
                        if 'network' in details_text:
                            change_data['changed_categories'].append('network')
                    
                    changes.append(change_data)
            
            logger.debug(f"üìù –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(changes)} –∑–∞–ø–∏—Å–µ–π –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π")
            return changes
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏—Å—Ç–æ—Ä–∏–∏ –∏–∑–º–µ–Ω–µ–Ω–∏–π: {e}")
            return []
    
    def _clean_text(self, text: str) -> str:
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        return re.sub(r'\s+', ' ', text).strip()
    
    def _extract_number(self, text: str) -> int:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —á–∏—Å–ª–æ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        try:
            # –£–¥–∞–ª—è–µ–º –∑–∞–ø—è—Ç—ã–µ –∏ –¥—Ä—É–≥–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–∏
            clean_text = re.sub(r'[^\d]', '', text)
            return int(clean_text) if clean_text else 0
        except (ValueError, TypeError):
            return 0
    
    def _parse_datetime(self, date_str: str) -> Optional[datetime]:
        """–ü–∞—Ä—Å–∏—Ç –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
        try:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
            formats = [
                "%d.%m.%Y %H:%M:%S",
                "%d.%m.%Y",
                "%Y-%m-%d %H:%M:%S",
                "%Y-%m-%d"
            ]
            
            for fmt in formats:
                try:
                    return datetime.strptime(date_str, fmt)
                except ValueError:
                    continue
            
            return None
            
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∞—Ç—É: {date_str} - {e}")
            return None
    
    def _extract_datetime_from_change(self, text: str) -> Optional[datetime]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞—Ç—É –∏–∑ —Å—Ç—Ä–æ–∫–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è"""
        try:
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω –¥–∞—Ç—ã –≤ —Ç–µ–∫—Å—Ç–µ
            date_pattern = r'(\d{2}\.\d{2}\.\d{4} \d{2}:\d{2}:\d{2})'
            match = re.search(date_pattern, text)
            
            if match:
                return self._parse_datetime(match.group(1))
            
            return None
            
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –¥–∞—Ç—É –∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è: {text} - {e}")
            return None
    
    def _extract_measurement_id(self, text: str) -> Optional[int]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç ID –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏–∑ —Å—Ç—Ä–æ–∫–∏"""
        try:
            # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω —Ç–∏–ø–∞ "#123"
            id_pattern = r'#(\d+)'
            match = re.search(id_pattern, text)
            
            if match:
                return int(match.group(1))
            
            return None
            
        except Exception as e:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å measurement ID: {text} - {e}")
            return None
    
    async def validate_html_structure(self, soup: BeautifulSoup) -> Dict[str, bool]:
        """
        –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É HTML –æ—Ç—á–µ—Ç–∞
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
        """
        validation = {
            'has_title': bool(soup.find('title')),
            'has_header': bool(soup.find(class_='header')),
            'has_navigation': bool(soup.find(class_='navigation')),
            'has_stats': bool(soup.find(class_='stats')),
            'has_connections_table': bool(soup.find(class_='connections-table')),
            'has_ports_grid': bool(soup.find(class_='ports-grid')),
            'has_nav_buttons': bool(soup.find(class_='nav-btn')),
        }
        
        validation['is_valid'] = all(validation.values())
        
        return validation


# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –ø–∞—Ä—Å–µ—Ä–∞
html_parser = AnalyzerHTMLParser()


async def parse_analyzer_html_file(file_path: str) -> Dict[str, Any]:
    """
    –í—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML —Ñ–∞–π–ª–∞ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
    
    Args:
        file_path: –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É
        
    Returns:
        –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ—Ç—á–µ—Ç–∞
    """
    return await html_parser.parse_html_report(file_path)


if __name__ == "__main__":
    """
    –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ HTML –æ—Ç—á–µ—Ç–æ–≤
    """
    import asyncio
    
    async def test_parser():
        test_file = "../Mac_darwin_report_analyzer.html"
        
        if os.path.exists(test_file):
            print(f"üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞—Ä—Å–µ—Ä–∞ –Ω–∞ —Ñ–∞–π–ª–µ: {test_file}")
            
            try:
                result = await parse_analyzer_html_file(test_file)
                
                print("‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω!")
                print(f"üìä Hostname: {result.get('hostname')}")
                print(f"üìä –°–æ–µ–¥–∏–Ω–µ–Ω–∏–π: {result.get('total_connections', 0)}")
                print(f"üìä TCP –ø–æ—Ä—Ç–æ–≤: {len(result.get('ports', {}).get('tcp', []))}")
                print(f"üìä UDP –ø–æ—Ä—Ç–æ–≤: {len(result.get('ports', {}).get('udp', []))}")
                print(f"üìä –°–µ—Ç–µ–≤—ã—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–æ–≤: {len(result.get('network_interfaces', []))}")
                print(f"üìä –ó–∞–ø–∏—Å–µ–π –∏–∑–º–µ–Ω–µ–Ω–∏–π: {len(result.get('change_history', []))}")
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è: {e}")
        else:
            print(f"‚ùå –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {test_file}")
    
    asyncio.run(test_parser()) 